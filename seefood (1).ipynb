{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seefood",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29203286964e49908d79ff28b6d2f77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_859d3fb562ed4395a36aa0e4a1d13d9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_194547b4eb424231b9230869550b7556",
              "IPY_MODEL_6a64ea4f8cb540a99aa75d5006192d05"
            ]
          }
        },
        "859d3fb562ed4395a36aa0e4a1d13d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "194547b4eb424231b9230869550b7556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00194aefd4f3421d8e80181dec5e10c8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3667509150548dba9e73d405c49e7da"
          }
        },
        "6a64ea4f8cb540a99aa75d5006192d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ffe095589744e3d9d1088efeeb3c9ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 63.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dbedaad5c8e47aa96d667bcda88c33a"
          }
        },
        "00194aefd4f3421d8e80181dec5e10c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3667509150548dba9e73d405c49e7da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ffe095589744e3d9d1088efeeb3c9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dbedaad5c8e47aa96d667bcda88c33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh9s0ahYHkEA"
      },
      "source": [
        "!pip install pytorch-ignite\n",
        "!pip install torch-lr-finder\n",
        "!wget https://xane-data.s3.ap-south-1.amazonaws.com/datasets/xane-ai/seefood.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOELqzAzl3rx"
      },
      "source": [
        "!tar -xvzf './seefood.tgz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4jzq6xoIW1m"
      },
      "source": [
        "!rm './seefood.tgz'\n",
        "!rm './seefood/.DS_Store'\n",
        "!rm './seefood/._.DS_Store'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeyUeooQIhEl"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_lr_finder import LRFinder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image, ImageDraw\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimage\n",
        "import os\n",
        "import cv2\n",
        "import torch.optim as optim\n",
        "from ignite.engine import create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss, Accuracy\n",
        "from ignite.contrib.handlers import FastaiLRFinder, ProgressBar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-7Ri63-Jkjm"
      },
      "source": [
        "path = \"seefood\"\n",
        "for folder in os.listdir(path):\n",
        "  for img_file in os.listdir(os.path.join(path,folder)):\n",
        "    img_file = os.path.join(path,folder,img_file)\n",
        "    try:\n",
        "      img = Image.open(img_file)\n",
        "      if img.mode!='RGB':\n",
        "        os.remove(img_file)\n",
        "        print(img_file)\n",
        "    except:\n",
        "      print(img_file)\n",
        "      os.remove(img_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkpvBc_GLFdh"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5],[0.5])\n",
        "                              ])\n",
        "transform2 = transforms.Compose([\n",
        "                                transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5],[0.5]),\n",
        "                                transforms.RandomRotation((0,90)),\n",
        "                                transforms.Grayscale(3)\n",
        "                              ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-IsUcnLqXQ"
      },
      "source": [
        "dataset1 = datasets.ImageFolder('seefood',transform=transform)\n",
        "dataset2 = datasets.ImageFolder('seefood',transform=transform2)\n",
        "dataset = dataset1 + dataset2\n",
        "dataset_len = len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9gGFow-OBH_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZTA9mYFMGWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a996693-b47f-4113-c8e2-bd60c0b25a59"
      },
      "source": [
        "train_len,test_len = dataset_len - 200,200\n",
        "train_set,test_set = torch.utils.data.random_split(dataset,[train_len,test_len],generator=torch.manual_seed(20))\n",
        "batch_size = 100\n",
        "train_set = DataLoader(dataset=train_set,shuffle=True,batch_size=batch_size)\n",
        "test_set = DataLoader(dataset=test_set,shuffle=True,batch_size=batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using Device: ', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Device:  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "29203286964e49908d79ff28b6d2f77a",
            "859d3fb562ed4395a36aa0e4a1d13d9d",
            "194547b4eb424231b9230869550b7556",
            "6a64ea4f8cb540a99aa75d5006192d05",
            "00194aefd4f3421d8e80181dec5e10c8",
            "d3667509150548dba9e73d405c49e7da",
            "6ffe095589744e3d9d1088efeeb3c9ef",
            "9dbedaad5c8e47aa96d667bcda88c33a"
          ]
        },
        "id": "vNRRSliuQqtz",
        "outputId": "7465688b-9362-4381-de0c-610fabe11bc2"
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29203286964e49908d79ff28b6d2f77a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfFrlGN2uleO"
      },
      "source": [
        "for param in model.parameters(): \n",
        "  param.requires_grid = False \n",
        "  model.fc = torch.nn.Linear(in_features=512,out_features=2,bias=True) \n",
        "  model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd-zDX5zfaAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052fd6db-fcfa-4f8f-dbd4-8af7ebfb6e3c"
      },
      "source": [
        "list(model.parameters())[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q1Z_kM4R0q-"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(model.parameters(),lr=5.34e-4,weight_decay=10e-5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvKEIUBK--bP"
      },
      "source": [
        "# lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "# lr_finder.range_test(train_set,start_lr=10e-5, end_lr=1, num_iter=100)\n",
        "# lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "# lr_finder.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOnU71w9SUfJ"
      },
      "source": [
        "model.train()\n",
        "for epoch in range(10):\n",
        "  total_correct = 0.0\n",
        "  running_loss = 0.0\n",
        "  for i,(inputs,labels) in enumerate(train_set):\n",
        "    inputs,labels = inputs.to(device),labels.to(device)\n",
        "    output = model(inputs)\n",
        "    output_idx = torch.argmax(output,dim=1)\n",
        "    total_correct+=(labels == output_idx).sum().item()\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output,labels)\n",
        "    running_loss+= loss.item()*inputs.size(0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'Epoch: {epoch} Loss = {running_loss/train_len} Accuracy:{(total_correct/train_len)*100}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUxUcguMYC7s"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0.0\n",
        "  for inputs,labels in test_set:\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs.to(device))\n",
        "    loss = criterion(outputs,labels)\n",
        "    total_loss = loss.item() * inputs.size(0)\n",
        "    output_idx = torch.argmax(outputs,dim=1)\n",
        "    total_correct+=sum(labels == output_idx)\n",
        "print(f'Loss = {running_loss/test_len} Accuracy:{(total_correct/test_len)*100}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np2QgQoXcwp_"
      },
      "source": [
        "torch.save(model.state_dict(),'hot_dog_vs_not_hot_dog.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKqLv66DC_ev"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import models,transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "labels = ['hot_dog','not_hot_dog']\n",
        "model_path = 'hot_dog_vs_not_hot_dog.pt'\n",
        "img_file_path = '/content/download.jpg'\n",
        "transform = transforms.Compose([transforms.CenterCrop(224),transforms.ToTensor()])\n",
        "model = models.resnet18()\n",
        "model.fc = torch.nn.Linear(in_features=512,out_features=len(labels),bias=True)\n",
        "model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "img = Image.open(img_file_path)\n",
        "img = transform(img)\n",
        "prediction = model(img.unsqueeze(0))\n",
        "print(prediction)\n",
        "result = torch.argmax(prediction)\n",
        "print(result)\n",
        "print(f'This is a {labels[result]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnMPo1REgRqS"
      },
      "source": [
        "import torch\n",
        "from torchvision import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VcoE8PLiPcX"
      },
      "source": [
        "pt_model = models.resnet18()\n",
        "pt_model.fc = torch.nn.Linear(in_features=512,out_features=2,bias=True)\n",
        "pt_model.load_state_dict(torch.load('hot_dog_vs_not_hot_dog.pt',map_location=torch.device('cpu')))\n",
        "\n",
        "dummy_input = torch.randn(64,3,224,224,device='cpu')\n",
        "torch.onnx.export(pt_model,               # model being run\n",
        "                  dummy_input,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"/content/onnx_model_hotdog.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJE8pQJDqXSw"
      },
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N938xlYKwqgT"
      },
      "source": [
        "import numpy\n",
        "import onnxruntime\n",
        "import onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bVDGzVHw6Cx"
      },
      "source": [
        "onnx_model = onnx.load(\"/content/onnx_model_hotdog.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT2qe1cy4b2r"
      },
      "source": [
        "ort_session = onnxruntime.InferenceSession(\"/content/onnx_model_hotdog.onnx\")\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcCditA5yWe"
      },
      "source": [
        "img_file_path = '/content/download.jpg'\n",
        "transform = transforms.Compose([transforms.CenterCrop(224),transforms.ToTensor()])\n",
        "img = Image.open(img_file_path)\n",
        "img = transform(img)\n",
        "img = img.unsqueeze(0)\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESbNu3CT55c9"
      },
      "source": [
        "np.argmax(ort_outs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}